# -*- coding: utf-8 -*-
"""HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fyBOuQhEcPwKgN8N-WRAR26gPrBkZyJG
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.formula.api as smf
from scipy.stats import t

sns.set(font_scale=1.5)
sns.set_style("whitegrid", {'grid.linestyle':'--'})

data = pd.read_csv("convertcsv1.csv")
data.head()

# Retrieve data as a numpy array
Y = data[["y"]].values
print(Y.shape)
Y[:5]

X = np.append(np.ones(shape=(data.shape[0], 1)), data[["x"]].values, axis=1)
print(X.shape)
X[:5]

# Calculates coefficients
betas = np.linalg.inv(X.T @ X) @ X.T @ Y
betas

# Calculates the standard error
Y_hat = X @ betas
residual = Y - Y_hat
var = np.var(residual, ddof=X.shape[1])

se = np.sqrt(var * np.linalg.inv(X.T @ X))
se

# Calculate significance of the result by confidence interval of slope
LCI= (betas[1]-1.96*se[1][1])
UCI= (betas[1]+1.96*se[1][1])
print("The lower bound of the 95% CI is:",LCI)
print("The upper bound of the 95% CI is:",UCI)

# Calculates R2
r2 = np.power(Y_hat - np.mean(Y), 2).sum() / np.power(Y - np.mean(Y), 2).sum()
r2

# confidence interval
x_new = 10

y_hat = (betas[0] + betas[1] * x_new)[0]
print(y_hat)

delta = np.sqrt(var) * np.sqrt(1 / X.shape[0] + (x_new - np.mean(X[:, 1]))**2 / np.sum((X[:, 1] - np.mean(X[:, 1]))**2))  
multiplier = 1.96
# multiplier = t.ppf(q=0.975, df=X.shape[0] - X.shape[1])

print(f"The lower bound of the 95% CI is: {y_hat - multiplier * delta:5.3f}")
print(f"The upper bound of the 95% CI is: {y_hat + multiplier * delta:5.3f}")

delta = np.sqrt(var) * np.sqrt(1 + 1 / X.shape[0] + (x_new - np.mean(X[:, 1]))**2 / np.sum((X[:, 1] - np.mean(X[:, 1]))**2))  

print(f"The lower bound of the 95% PI is: {y_hat - multiplier * delta:5.3f}")
print(f"The upper bound of the 95% PI is: {y_hat + multiplier * delta:5.3f}")

# problem 2

data = pd.read_csv("convertcsv1.csv")
data.head()

# Retrieve data as a numpy array
Y = data[["y"]].values
print(Y.shape)
Y[:5]

X = data[["x", "x2"]].values
X = np.append(np.ones((X.shape[0], 1)), X, axis=1)
print(X.shape)
X[:5]

# Calculates coefficients
betas = np.linalg.inv(X.T @ X) @ X.T @ Y
betas

Y_hat = X @ betas
residual = Y - Y_hat
var = np.var(residual, ddof=X.shape[1])

se = np.sqrt(var * np.linalg.inv(X.T @ X))
se

# Calculates R2
r2 = np.power(Y_hat - np.mean(Y), 2).sum() / np.power(Y - np.mean(Y), 2).sum()
r2

# Linear regression with the `statsmodels` library
model_1 = smf.ols(formula='y ~ x + x2', data=data)
result_1 = model_1.fit()
print(result_1.summary())